{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating hurricane tracks using big data analytics\n",
    "\n",
    "The sample code below uses big data analytics (GeoAnalytics) to reconstruct hurricane tracks using data registered on a big data file share in the GIS.\n",
    "\n",
    "## Reconstruct tracks\n",
    "Reconstruct tracks is a type of data aggregation tool available under big data tools. This tool works with a layer of point features or polygon features that are time enabled. It first determines which points belong to a track using an identification number or identification string. Using the time at each location, the tracks are ordered sequentially and transformed into a line representing the path of movement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the data attributes\n",
    "Let us read the subset as a FeatureLayer to view its attribute table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ATC_eye</th>\n",
       "      <th>ATC_grade</th>\n",
       "      <th>ATC_poci</th>\n",
       "      <th>ATC_pres</th>\n",
       "      <th>ATC_rmw</th>\n",
       "      <th>ATC_roci</th>\n",
       "      <th>ATC_w34_r1</th>\n",
       "      <th>ATC_w34_r2</th>\n",
       "      <th>ATC_w34_r3</th>\n",
       "      <th>ATC_w34_r4</th>\n",
       "      <th>...</th>\n",
       "      <th>basin_1</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>min_</th>\n",
       "      <th>month</th>\n",
       "      <th>wmo_pres</th>\n",
       "      <th>wmo_pres__</th>\n",
       "      <th>wmo_wind</th>\n",
       "      <th>wmo_wind__</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-999</td>\n",
       "      <td>-999.</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>...</td>\n",
       "      <td>SI</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>1932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-999</td>\n",
       "      <td>-999.</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>...</td>\n",
       "      <td>SI</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>1932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-999</td>\n",
       "      <td>-999.</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>...</td>\n",
       "      <td>SI</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>1932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-999</td>\n",
       "      <td>-999.</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>...</td>\n",
       "      <td>SI</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>1932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ATC_eye ATC_grade  ATC_poci  ATC_pres  ATC_rmw  ATC_roci  ATC_w34_r1  \\\n",
       "0     -999     -999.      -999      -999     -999      -999        -999   \n",
       "1     -999     -999.      -999      -999     -999      -999        -999   \n",
       "2     -999     -999.      -999      -999     -999      -999        -999   \n",
       "3     -999     -999.      -999      -999     -999      -999        -999   \n",
       "\n",
       "   ATC_w34_r2  ATC_w34_r3  ATC_w34_r4  ...   basin_1  day  hour  min_  month  \\\n",
       "0        -999        -999        -999  ...        SI    1     0     0      1   \n",
       "1        -999        -999        -999  ...        SI    1     6     0      1   \n",
       "2        -999        -999        -999  ...        SI    1    12     0      1   \n",
       "3        -999        -999        -999  ...        SI    1    18     0      1   \n",
       "\n",
       "   wmo_pres  wmo_pres__  wmo_wind  wmo_wind__  year  \n",
       "0      -999        -999      -999        -999  1932  \n",
       "1         0        -100         0        -100  1932  \n",
       "2      -999        -999      -999        -999  1932  \n",
       "3      -999        -999      -999        -999  1932  \n",
       "\n",
       "[4 rows x 147 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from arcgis.lyr import FeatureService\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "subset_FS = FeatureService(subset_search[0].url, ago_gis)\n",
    "subset_FL = subset_FS.layers[0]\n",
    "\n",
    "query_result = subset_FL.query(where ='FID < 5', \n",
    "                                out_fields = \"*\", \n",
    "                                returnGeometry = False)\n",
    "\n",
    "att_data_frame = json_normalize(query_result)\n",
    "att_data_frame.columns = att_data_frame.columns.str.replace(\"attributes.\",\"\")\n",
    "att_data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a data store\n",
    "For the GeoAnalytics server to process your big data, it needs the data to be registered as a data store. In our case, the data is in multiple shape files and we will register the folder containing the files as a data store of type `bigDataFileShare`.\n",
    "\n",
    "Let us connect to an ArcGIS Enterprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BigDataTools url:\"https://dev002857.esri.com/arcgis/rest/services/System/GeoAnalyticsTools/GPServer\">"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from arcgis.gis import *\n",
    "gis = GIS(\"https://dev002759.esri.com/portal\",\"admin\",\"esri.agp\")\n",
    "\n",
    "# find the server running GeoAnalytics\n",
    "ga_tools = gis.tools.bigdata\n",
    "ga_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datastores property of GIS provides you with a list of DatastoreManager objects, one for each server federated with the portal. This object allows you to query, inspect and manipulate the datastores available to your ArcGIS Server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<DatastoreManager for https://Dev002759.esri.com:6443/arcgis/admin>,\n",
       " <DatastoreManager for https://dev002857.esri.com:6443/arcgis/admin>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query the DataStoreManager objects available to the portal\n",
    "data_mgr_bysite = gis.datastores\n",
    "data_mgr_bysite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Datastore title:\"/bigDataFileShares/Chicago_accidents\" type:\"bigDataFileShare\">,\n",
       " <Datastore title:\"/bigDataFileShares/ht_ui2\" type:\"bigDataFileShare\">,\n",
       " <Datastore title:\"/bigDataFileShares/ht_ui3\" type:\"bigDataFileShare\">,\n",
       " <Datastore title:\"/bigDataFileShares/ht_ui5\" type:\"bigDataFileShare\">]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the data stores registered on the GeoAnalytics server\n",
    "data_store_mgr = data_mgr_bysite[1]\n",
    "data_store_mgr.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Big Data file share for full_dataset\n"
     ]
    }
   ],
   "source": [
    "data_item = data_store_mgr.add_bigdata(\"full_dataset\", \"\\\\teton\\atma_shared\\datasets\\Esri_Geoanalytics_datasets\\hurricanes\\entire_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a big data file share is created, the GeoAnalytics server processes all the valid file types to discern the schema of the data. This process can take a few minutes depending on the size of your data. Once processed, querying the manifest property returns the schema. As you can see from below, the schema is similar to the subset we observed earlier in this sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_item = data_store_mgr.search()[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform data aggregation using reconstruct tracks tool\n",
    "When you add a big data file share datastore, a corresponding item gets created on your portal. You can search for it like a regular item and query its layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Item title:\"bigDataFileShares_ht_ui5\" type:Big Data File Share owner:admin>,\n",
       " <Item title:\"bigDataFileShares_ht_ui2\" type:Big Data File Share owner:admin>,\n",
       " <Item title:\"bigDataFileShares_Chicago_accidents\" type:Big Data File Share owner:admin>,\n",
       " <Item title:\"bigDataFileShares_ht_ui3\" type:Big Data File Share owner:admin>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result = gis.content.search(\"\", item_type = \"big data file share\")\n",
    "search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_item = search_result[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://dev002857.esri.com/arcgis/rest/services/DataStoreCatalogs/bigDataFileShares_ht_ui3/BigDataCatalogServer'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_item.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Layer url:\"https://dev002857.esri.com/arcgis/rest/services/DataStoreCatalogs/bigDataFileShares_ht_ui3/BigDataCatalogServer/h1842_h1852\">,\n",
       " <Layer url:\"https://dev002857.esri.com/arcgis/rest/services/DataStoreCatalogs/bigDataFileShares_ht_ui3/BigDataCatalogServer/h1852_h1862\">,\n",
       " <Layer url:\"https://dev002857.esri.com/arcgis/rest/services/DataStoreCatalogs/bigDataFileShares_ht_ui3/BigDataCatalogServer/h1862_h1872\">,\n",
       " <Layer url:\"https://dev002857.esri.com/arcgis/rest/services/DataStoreCatalogs/bigDataFileShares_ht_ui3/BigDataCatalogServer/h1872_h1882\">,\n",
       " <Layer url:\"https://dev002857.esri.com/arcgis/rest/services/DataStoreCatalogs/bigDataFileShares_ht_ui3/BigDataCatalogServer/h1882_h1892\">,\n",
       " <Layer url:\"https://dev002857.esri.com/arcgis/rest/services/DataStoreCatalogs/bigDataFileShares_ht_ui3/BigDataCatalogServer/h1892_h1902\">,\n",
       " <Layer url:\"https://dev002857.esri.com/arcgis/rest/services/DataStoreCatalogs/bigDataFileShares_ht_ui3/BigDataCatalogServer/h1902_h1912\">,\n",
       " <Layer url:\"https://dev002857.esri.com/arcgis/rest/services/DataStoreCatalogs/bigDataFileShares_ht_ui3/BigDataCatalogServer/h1912_h1922\">,\n",
       " <Layer url:\"https://dev002857.esri.com/arcgis/rest/services/DataStoreCatalogs/bigDataFileShares_ht_ui3/BigDataCatalogServer/h1922_h1932\">,\n",
       " <Layer url:\"https://dev002857.esri.com/arcgis/rest/services/DataStoreCatalogs/bigDataFileShares_ht_ui3/BigDataCatalogServer/h1932_h1942\">]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_item.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "years_1842_52 = data_item.layers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruct tracks tool\n",
    "\n",
    "The `reconstruct_tracks()` tool can be accessed through the tools.bigdata property of your GIS. In this example, we are using this tool to aggregate the numerous points into line segments showing the tracks followed by the hurricanes. The tool creates a feature service as an output which can be accessed once the processing is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted.\n",
      "Executing...\n",
      "Executing (ReconstructTracks): ReconstructTracks \"Feature Set\" Serial_Num Geodesic # # # # {\"serviceProperties\":{\"name\":\"hurricane_tracks_agg_result\",\"serviceUrl\":\"http://Dev002759.esri.com/server/rest/services/Hosted/hurricane_tracks_agg_result/FeatureServer\"},\"itemProperties\":{\"itemId\":\"94d90259707f4977a74cc8af479ae208\"}} {}\n",
      "Start Time: Sun Oct 16 18:51:33 2016\n",
      "Using URL based GPRecordSet param: https://dev002857.esri.com/arcgis/rest/services/DataStoreCatalogs/bigDataFileShares_ht_ui3/BigDataCatalogServer/h1842_h1852\n",
      "{\"messageCode\":\"BD_101028\",\"message\":\"Starting new distributed job with 3 tasks.\",\"params\":{\"totalTasks\":\"3\"}}\n",
      "{\"messageCode\":\"BD_101029\",\"message\":\"1/3 distributed tasks completed.\",\"params\":{\"completedTasks\":\"1\",\"totalTasks\":\"3\"}}\n",
      "{\"messageCode\":\"BD_101029\",\"message\":\"2/3 distributed tasks completed.\",\"params\":{\"completedTasks\":\"2\",\"totalTasks\":\"3\"}}\n",
      "{\"messageCode\":\"BD_101029\",\"message\":\"3/3 distributed tasks completed.\",\"params\":{\"completedTasks\":\"3\",\"totalTasks\":\"3\"}}\n",
      "Finished writing\n",
      "  extent = Some(Envelope: [-100.19999694824219, -34.5, 88.5999984741211, 48.5])\n",
      "  interval = Some(Interval(MutableInstant(1842-10-25 06:00:00.000),MutableInstant(1852-10-11 18:00:00.000)))\n",
      "  count = 27\n"
     ]
    }
   ],
   "source": [
    "agg_result = gis.tools.bigdata.reconstruct_tracks(years_1842_52,\n",
    "                                                 track_fields = 'Serial_Num',\n",
    "                                                 output_name = 'hurricane_tracks_agg_result',\n",
    "                                                 method = 'GEODESIC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the results\n",
    "Let us create a map and load the processed result which is a feature service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_map = gis.map(\"USA\",2)\n",
    "processed_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Item title:\"hurricane_tracks_agg_result\" type:Feature Service owner:admin>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr = gis.content.search(\"hurricane_tracks_agg_result\")\n",
    "sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_map.add_layer(sr[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we transformed a bunch of ponints into tracks that represents paths taken by the hurricanes over a period of 50 years. We can pull up another map and inspect the results a bit more closely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map2 = gis.map('USA', 2)\n",
    "map2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FeatureLayer url:\"http://portalname.domain.com/server/rest/services/Hosted/hurricane_tracks_agg_result/FeatureServer/0\">"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_layer = FeatureService(sr[0].url, gis).layers[0]\n",
    "tracks_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map2.add_layer(tracks_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our input data and the map widget is time enabled. Thus we can filter the data to represent the tracks from only the years 1852 to 1860"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_map.start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map2.start_time = '1852'\n",
    "map2.end_time = '1860'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-76082966e054>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                                 returnGeometry = False)\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0matt_data_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0matt_data_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matt_data_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"attributes.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0matt_data_frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\envs\\geosaurus_gold\\lib\\site-packages\\pandas\\io\\json.py\u001b[0m in \u001b[0;36mjson_normalize\u001b[0;34m(data, record_path, meta, meta_prefix, record_prefix)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrecord_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitervalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0;31m# naive normalization, this is idempotent for flat records\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[0;31m# and potentially will inflate the data considerably for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from arcgis.lyr import FeatureService\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "subset_FS = FeatureService(sr[0].url, gis)\n",
    "subset_FL = subset_FS.layers[0]\n",
    "\n",
    "query_result = subset_FL.query(where ='FID < 5', \n",
    "                                out_fields = \"*\", \n",
    "                                returnGeometry = False)\n",
    "\n",
    "att_data_frame = json_normalize(query_result)\n",
    "att_data_frame.columns = att_data_frame.columns.str.replace(\"attributes.\",\"\")\n",
    "att_data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What can big data tools do for you?\n",
    "\n",
    "With this sample we just scratched the surface of what big data analysis can do for you. ArcGIS Enterprise at 10.5 packs a powerful set of tools that let you derive a lot of value from your data. You can do so by asking the right questions, for instance, a weather dataset such as this could be used to answer a few interesting questions such as\n",
    " \n",
    " - did the number of hurricanes per season increase over the years?\n",
    " - give me the hurricanes that travelled longest distance\n",
    " - give me the ones that stayed for longest time. Do we see a trend?\n",
    " - how are wind speed and distance travelled correlated?\n",
    " - my assets are located in a tornado corridor. How many times in the past century, was there a hurricane within 50 miles from my assets?\n",
    " - my industry is dependent on tourism, which is heavily impacted by the vagaries of weather. From historical weather data, can I correlate my profits with major weather events? How well is my business insulated from freak weather events?\n",
    " - over the years do we see any shifts in major weather events - do we notice a shift in when the hurricane season starts?\n",
    " \n",
    "The ArcGIS Python API gives you a gateway to easily access the big data tools from your ArcGIS Enterprise. By combining it with other powerful libraries from the pandas and scipy stack and the rich visualization capabilities of the Jupyter notebook, you can extract a lot of value from your data, big or small."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "e93d2b573d7a4dffaa6fc8309bcf7806": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
