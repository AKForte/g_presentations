{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data for Georgria boundary\n",
    "We have previously listed, downloaded hailstorm data from NCDC site. Next we cleaned this data to weed out bad measurements. We extracted these CSV files and imported that into the GIS as feature classes. Now we will extract the data only for the state of Georgia by doing a boundary clipping operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from pathlib import Path\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the input dataset paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_gdb = r'E:\\GIS_Data\\Analytics\\Georgia_hailstones\\decades_data_pro\\decades_data_pro.gdb'\n",
    "input_boundary = r'E:\\GIS_Data\\Analytics\\Georgia_hailstones\\decades_data_pro\\\\'+\\\n",
    "                'decades_hail_Georgia.gdb\\Georgia_boundary'\n",
    "output_fd = r'E:\\GIS_Data\\Analytics\\Georgia_hailstones\\decades_data_pro\\\\'+\\\n",
    "            'decades_hail_Georgia.gdb\\hail_gcs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clip to Georgia boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#first list all datasets in input geodatabase\n",
    "arcpy.env.workspace = input_gdb\n",
    "fc_list = arcpy.ListFeatureClasses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting hail_1997 | done\n",
      "Extracting hail_1998 | done\n",
      "Extracting hail_1999 | done\n",
      "Extracting hail_2000 | done\n",
      "Extracting hail_2001 | done\n",
      "Extracting hail_2002 | done\n",
      "Extracting hail_2003 | done\n",
      "Extracting hail_2004 | done\n",
      "Extracting hail_2005 | done\n",
      "Extracting hail_2006 | done\n",
      "Extracting hail_2007 | done\n",
      "Extracting hail_2008 | done\n",
      "Extracting hail_2009 | done\n",
      "Extracting hail_2010 | done\n",
      "Extracting hail_2011 | done\n",
      "Extracting hail_2012 | done\n",
      "Extracting hail_2013 | done\n",
      "Extracting hail_2014 | done\n",
      "Extracting hail_2015 | done\n",
      "Extracting hail_2016 | done\n"
     ]
    }
   ],
   "source": [
    "for fc in fc_list:\n",
    "    print(\"Extracting \" + fc, end=\" | \")\n",
    "    output_fc = output_fd + \"\\\\\" + fc\n",
    "    arcpy.analysis.Clip(fc, input_boundary, output_fc, None)\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us list the contents of destination geodatabase to ensure data is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hail_1997\n",
      "hail_1998\n",
      "hail_1999\n",
      "hail_2000\n",
      "hail_2001\n",
      "hail_2002\n",
      "hail_2003\n",
      "hail_2004\n",
      "hail_2005\n",
      "hail_2006\n",
      "hail_2007\n",
      "hail_2008\n",
      "hail_2009\n",
      "hail_2010\n",
      "hail_2011\n",
      "hail_2012\n",
      "hail_2013\n",
      "hail_2014\n",
      "hail_2015\n",
      "hail_2016\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = output_fd\n",
    "fc_list = arcpy.ListFeatureClasses()\n",
    "for fc in fc_list:\n",
    "    print(fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that data has been clipped to a smaller extend, further processing will be much faster and can be conducted just to this extent.\n",
    "\n",
    "## Convert the time field\n",
    "Let us list the fields in one our dataset and see if any of it has to be converted to a useful format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBJECTID | OID\n",
      "Shape | Geometry\n",
      "Field1 | Integer\n",
      "F_ZTIME | Double\n",
      "LON | Double\n",
      "LAT | Double\n",
      "WSR_ID | String\n",
      "CELL_ID | String\n",
      "RANGE | Integer\n",
      "AZIMUTH | Integer\n",
      "SEVPROB | Integer\n",
      "PROB | Integer\n",
      "MAXSIZE | Double\n",
      "time_dates | Date\n"
     ]
    }
   ],
   "source": [
    "fc1_fields = arcpy.ListFields(fc_list[0])\n",
    "for field in fc1_fields:\n",
    "    print(field.name + \" | \" + field.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : hail_1998 | done\n",
      "Processing : hail_1999 | done\n",
      "Processing : hail_2000 | done\n",
      "Processing : hail_2001 | done\n",
      "Processing : hail_2002 | done\n",
      "Processing : hail_2003 | done\n",
      "Processing : hail_2004 | done\n",
      "Processing : hail_2005 | done\n",
      "Processing : hail_2006 | done\n",
      "Processing : hail_2007 | done\n",
      "Processing : hail_2008 | done\n",
      "Processing : hail_2009 | done\n",
      "Processing : hail_2010 | done\n",
      "Processing : hail_2011 | done\n",
      "Processing : hail_2012 | done\n",
      "Processing : hail_2013 | done\n",
      "Processing : hail_2014 | done\n",
      "Processing : hail_2015 | done\n",
      "Processing : hail_2016 | done\n"
     ]
    }
   ],
   "source": [
    "#loop through each feature class except first, \n",
    "# create a new time field and process the data from F_ZTIME field\n",
    "fc_list = arcpy.ListFeatureClasses()\n",
    "for fc in fc_list[1:]:\n",
    "    print(\"Processing : \" + fc, end=\" | \")\n",
    "    arcpy.management.ConvertTimeField(fc, \"F_ZTIME\", \"yyyyMMdd\", \"time_dates\", \"DATE\", \"Not Used\")\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project the data\n",
    "The data downloaded from NCDC site is in geographic coordinate system. To process this in spatial analyst, we need to project this dataset so distances can be easily measured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_gdb = r'E:\\GIS_Data\\Analytics\\Georgia_hailstones\\decades_data_pro\\\\'+\\\n",
    "                'decades_hail_Georgia.gdb'\n",
    "\n",
    "output_spatial_reference = \"PROJCS['WGS_1984_Web_Mercator_Auxiliary_Sphere', \"+\\\n",
    "                        \"GEOGCS['GCS_WGS_1984',DATUM['D_WGS_1984',\"+\\\n",
    "                        \"SPHEROID['WGS_1984',6378137.0,298.257223563]],\"+\\\n",
    "                        \"PRIMEM['Greenwich',0.0],UNIT['Degree',0.0174532925199433]],\"+\\\n",
    "                        \"PROJECTION['Mercator_Auxiliary_Sphere'],PARAMETER['False_Easting',0.0],\"+\\\n",
    "                        \"PARAMETER['False_Northing',0.0],PARAMETER['Central_Meridian',0.0],\"+\\\n",
    "                        \"PARAMETER['Standard_Parallel_1',0.0],PARAMETER['Auxiliary_Sphere_Type',0.0],\"+\\\n",
    "                        \"UNIT['Meter',1.0]]\"\n",
    "transformation = None\n",
    "input_spatial_reference = \"GEOGCS['GCS_WGS_1984',DATUM['D_WGS_1984',\"+\\\n",
    "                        \"SPHEROID['WGS_1984',6378137.0,298.257223563]],\"+\\\n",
    "                        \"PRIMEM['Greenwich',0.0],UNIT['Degree',0.0174532925199433]]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create a timer so see how long each of these processing takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def my_timer(start_time):\n",
    "    now_time = time.time()\n",
    "    elapsed = now_time - start_time\n",
    "    \n",
    "    hours, rem = divmod(elapsed, 3600)\n",
    "    mins, sec = divmod(rem, 60)\n",
    "    \n",
    "    return \"{0}:{1}:{2}\".format(int(hours), int(mins), int(sec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projecting hail_1997 | done : 0:0:12\n",
      "Projecting hail_1998 | done : 0:0:13\n",
      "Projecting hail_1999 | done : 0:0:12\n",
      "Projecting hail_2000 | done : 0:0:10\n",
      "Projecting hail_2001 | done : 0:0:10\n",
      "Projecting hail_2002 | done : 0:0:5\n",
      "Projecting hail_2003 | done : 0:0:28\n",
      "Projecting hail_2004 | done : 0:0:23\n",
      "Projecting hail_2005 | done : 0:0:25\n",
      "Projecting hail_2006 | done : 0:0:27\n",
      "Projecting hail_2007 | done : 0:0:27\n",
      "Projecting hail_2008 | done : 0:0:27\n",
      "Projecting hail_2009 | done : 0:0:26\n",
      "Projecting hail_2010 | done : 0:0:26\n",
      "Projecting hail_2011 | done : 0:0:27\n",
      "Projecting hail_2012 | done : 0:0:27\n",
      "Projecting hail_2013 | done : 0:0:17\n",
      "Projecting hail_2014 | done : 0:0:18\n",
      "Projecting hail_2015 | done : 0:0:25\n",
      "Projecting hail_2016 | done : 0:0:20\n"
     ]
    }
   ],
   "source": [
    "for fc in fc_list:\n",
    "    start_time = time.time()\n",
    "    print(\"Projecting \" + fc, end=\" | \")\n",
    "    out_name = out_gdb + \"\\\\hail_webmerc\" + fc\n",
    "    arcpy.management.Project(in_dataset = fc, out_dataset = out_name,\n",
    "                            out_coor_system = output_spatial_reference, transform_method= None,\n",
    "                            in_coor_system = input_spatial_reference)\n",
    "    \n",
    "    print(\"done : \" + my_timer(start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:arcgispro-py3]",
   "language": "python",
   "name": "conda-env-arcgispro-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
